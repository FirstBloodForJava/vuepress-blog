# Hadoop

**大数据概述**：大数据 4 个显著特征，数据量大(Volume)、数据处理速度快(Velocity)、数据类型多样(Variety)、数据真实性(Veracity)；称为 4V。

- 数据量大：通常以 PB(Petabyte)、EB(Exabyte) 甚至 ZB(Zettabyte)为单位衡量。
- 数据处理速度快：传统的数据处理以小时、天甚至周为单位。大数据时代，数据的处理速度通常要求以秒甚至毫秒为单位。
- 数据类型多样：窗体数据处理通常以结构化的形式存在，如关系型数据库中的表格数据。大数据时代，数据的类型变得越来越多样化，包括结构化数据、**半结构化数据**和**非结构化数据**。
- 数据真实性：由于数据量的庞大和类型的多样性，数据的质量和真实性变得越来越难以保证。数据中可能存在错误、缺失、重复或不一致的情况，这些都会影响数据分析的结构和决策的准确性。因此，在大数据处理中，需要采用相应的技术手段对数据进行清洗、**验证**和**纠错**，以提高数据的真实性和可靠性。



## Hadoop概述

Hadoop 是一个开源的、可靠的、可扩展的分布式计算框架，由 Apache 软件基金会开发。它的核心设计目标是能够以一种可靠、高效、可伸缩的方式处理海量数据（GB到PB级别），尤其是在普通的、低成本的硬件集群上。

**Hadoop 优势**

- 可扩展性：分布式架构，增加节点扩展 Hadoop 集群的计算能力。
- 灵活性：支持多种数据格式和数据源；支持多种编程模型和计算框架。
- 开源软件。

**计算模型**：Hadoop 基于 MapReduce 计算模型，该模型是一种函数式编程的批处理框架。

**适用场景**：Hadoop 适用于离线数据分析和批处理任务，如日志分析、离线报表生成。

**Hadoop 的核心组件**：HDFS、YARN和MapReduce。

- HDFS(分布式文件系统)：用于存储和管理大规模数据。
- YARN(资源管理器)：负责资源的分配与任务调度。
- MapReduce(编程模型)：用于编写分布式计算任务。



