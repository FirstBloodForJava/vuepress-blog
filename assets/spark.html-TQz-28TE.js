import{_ as s,c as n,e as t,o as e}from"./app-DO9Fsueg.js";const p={};function l(o,a){return e(),n("div",null,a[0]||(a[0]=[t(`<h1 id="spark" tabindex="-1"><a class="header-anchor" href="#spark"><span>Spark</span></a></h1><p>Spark 文档版本选择：https://spark.apache.org/documentation.html</p><p>Spark-3.5.6 版本：https://spark.apache.org/docs/3.5.6/</p><p>Spark 下载地址：https://spark.apache.org/downloads.html</p><p>Spark-submit 文档：https://spark.apache.org/docs/3.5.6/submitting-applications.html</p><h2 id="spark-介绍" tabindex="-1"><a class="header-anchor" href="#spark-介绍"><span>Spark 介绍</span></a></h2><p>在 Spark 2.0 之前，Spark 的主要编程接口是 RDD(Resilient Distributed Dataset)，在 Spark 2.0 之后，RDD 被 Dataset 取代，Dataset 像 RDD 一样具有强类型，但进行了更丰富的优化。</p><p>Spark Application 由 SparkContext 对象协调，在集群中作为独立进程运行。</p><p>要在集群上运行，SparkContext 需要连接集群管理器(Spark standalone、Apache Mesos、YARN、Kubernetes)，支持跨应用运行。连接后，Spark 获取节点上的执行器，这些节点就是计算和存储数据的进程。接下来，SparkContext 将应用代码发送到执行器，最后，SparkContext 将任务发送到执行器运行。</p><figure><img src="http://47.101.155.205/image-20250920100628994.png" alt="image-20250920100628994" tabindex="0" loading="lazy"><figcaption>image-20250920100628994</figcaption></figure><p>注意：</p><ol><li>每个 Application 都有自己的执行器进程，这些进程在整个应用程序的持续时间内保持运行状态，并在多个线程中运行任务。这样做的好处是，在调度端(Driver)和执行器端(Task)，应用程序彼此隔离。但是，这也意味着如果不将数据写入外部存储系统，则无法在不同的 Spark 应用程序(SparkContext 的实例)之间共享数据。</li><li>Spark 与底层集群管理器无关。</li><li>Driver 要与 Executor互通。</li><li>Driver 和 Worker Node 最好在同一局域网运行。</li></ol><p><strong>术语介绍：</strong></p><table><thead><tr><th>术语</th><th>含义</th></tr></thead><tbody><tr><td>Application</td><td>基于 Spark 构建的用户程序。</td></tr><tr><td>Application jar</td><td>包含用户的 Spark 应用程序的 jar</td></tr><tr><td>Driver program</td><td>运行 application main方法并创建 SparkContext 的进程</td></tr><tr><td>Cluster manager</td><td>用于获取集群资源的外部服务</td></tr><tr><td>Deploy mode</td><td>区分驱动程序进程的运行位置。在 Cluster 模式下，框架在集群内部启动驱动程序。在 Client 模式下，提交者在集群外部启动驱动程序。</td></tr><tr><td>Worker node</td><td>可以在集群中运行应用程序代码的任何节点</td></tr><tr><td>Executor</td><td>为工作节点上的应用程序启动的进程，用于运行任务并将数据保存在内存或磁盘存储中。每个应用程序都有自己的执行器。</td></tr><tr><td>Task</td><td>将发送给一个执行程序的工作单元</td></tr><tr><td>Job</td><td>响应 Spark action 而生成的多个任务组成的并行计算</td></tr><tr><td>Stage</td><td>每个 Job 都被分成一组更小的任务，称为阶段，这些阶段相互依赖</td></tr></tbody></table><h2 id="quick-start" tabindex="-1"><a class="header-anchor" href="#quick-start"><span>Quick Start</span></a></h2><p>Spark Shell 提供了 Scala 和 Python 命令行运行 API 的方式：bin/pyspark、bin/spark-shell</p><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh" data-title="sh"><pre><code><span class="line"><span class="token comment"># 从文件创建数据集</span></span>
<span class="line">val textFile <span class="token operator">=</span> spark.read.textFile<span class="token punctuation">(</span><span class="token string">&quot;D:<span class="token entity" title="\\\\">\\\\</span>spark<span class="token entity" title="\\\\">\\\\</span>spark-3.5.6-bin-hadoop3<span class="token entity" title="\\\\">\\\\</span>README.md&quot;</span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line"><span class="token comment"># Dataset 的总数</span></span>
<span class="line">textFile.count<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line"><span class="token comment"># Dataset 第一行数据</span></span>
<span class="line">textFile.first<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line"><span class="token comment"># transform Dataset, 过滤</span></span>
<span class="line">val linesWithSpark <span class="token operator">=</span> textFile.filter<span class="token punctuation">(</span>line <span class="token operator">=</span><span class="token operator">&gt;</span> line.contains<span class="token punctuation">(</span><span class="token string">&quot;Spark&quot;</span><span class="token punctuation">))</span></span>
<span class="line"></span>
<span class="line"><span class="token comment"># 包含 Spark 总行数</span></span>
<span class="line">textFile.filter<span class="token punctuation">(</span>line <span class="token operator">=</span><span class="token operator">&gt;</span> line.contains<span class="token punctuation">(</span><span class="token string">&quot;Spark&quot;</span><span class="token punctuation">))</span>.count<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span class="token comment"># Dateset 操作, 获取单词数最多行总数</span></span>
<span class="line">textFile.map<span class="token punctuation">(</span>line <span class="token operator">=</span><span class="token operator">&gt;</span> line.split<span class="token punctuation">(</span><span class="token string">&quot; &quot;</span><span class="token punctuation">)</span>.size<span class="token punctuation">)</span>.reduce<span class="token variable"><span class="token punctuation">((</span>a<span class="token punctuation">,</span> b<span class="token punctuation">)</span> <span class="token operator">=</span><span class="token operator">&gt;</span> if <span class="token punctuation">(</span>a <span class="token operator">&gt;</span> b<span class="token punctuation">)</span> a else b<span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line"># 导入 java 类</span>
<span class="line">import java.lang.Math</span>
<span class="line">textFile.map<span class="token punctuation">(</span>line <span class="token operator">=</span><span class="token operator">&gt;</span> line.split<span class="token punctuation">(</span>&quot; &quot;<span class="token punctuation">)</span>.size<span class="token punctuation">)</span>.reduce<span class="token punctuation">((</span>a<span class="token punctuation">,</span> b<span class="token punctuation">)</span> <span class="token operator">=</span><span class="token operator">&gt;</span> Math.max<span class="token punctuation">(</span>a<span class="token punctuation">,</span> b<span class="token punctuation">))</span></span></span>
<span class="line"></span>
<span class="line"><span class="token comment"># 统计单词数</span></span>
<span class="line">val wordCounts <span class="token operator">=</span> textFile.flatMap<span class="token punctuation">(</span>line <span class="token operator">=</span><span class="token operator">&gt;</span> line.split<span class="token punctuation">(</span><span class="token string">&quot; &quot;</span><span class="token punctuation">))</span>.groupByKey<span class="token punctuation">(</span>identity<span class="token punctuation">)</span>.count<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">wordCounts.collect<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span class="token comment"># 缓存数据</span></span>
<span class="line">linesWithSpark.cache<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><figure><img src="http://47.101.155.205/image-20250920185850717.png" alt="image-20250920185850717" tabindex="0" loading="lazy"><figcaption>image-20250920185850717</figcaption></figure><figure><img src="http://47.101.155.205/image-20250920193211753.png" alt="image-20250920193211753" tabindex="0" loading="lazy"><figcaption>image-20250920193211753</figcaption></figure><h3 id="自定义-application" tabindex="-1"><a class="header-anchor" href="#自定义-application"><span>自定义 Application</span></a></h3><p>gradle 和 gradle 项目可以通过 <code>shadow</code> 插件将项目依赖打包至 jar中。</p><p>将 <code>examples\\src\\main\\java</code> 代码拷贝至新的 maven 项目中。</p><p>maven 项目配置如下。</p><div class="language-xml line-numbers-mode" data-highlighter="prismjs" data-ext="xml" data-title="xml"><pre><code><span class="line"><span class="token prolog">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span></span>
<span class="line"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>project</span> <span class="token attr-name">xmlns</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">&quot;</span>http://maven.apache.org/POM/4.0.0<span class="token punctuation">&quot;</span></span></span>
<span class="line">         <span class="token attr-name"><span class="token namespace">xmlns:</span>xsi</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">&quot;</span>http://www.w3.org/2001/XMLSchema-instance<span class="token punctuation">&quot;</span></span></span>
<span class="line">         <span class="token attr-name"><span class="token namespace">xsi:</span>schemaLocation</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">&quot;</span>http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd<span class="token punctuation">&quot;</span></span><span class="token punctuation">&gt;</span></span></span>
<span class="line">    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>modelVersion</span><span class="token punctuation">&gt;</span></span>4.0.0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>modelVersion</span><span class="token punctuation">&gt;</span></span></span>
<span class="line"></span>
<span class="line">    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>org.apache.spark.examples<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span></span>
<span class="line">    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>spark-example<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span></span>
<span class="line">    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">&gt;</span></span>1.0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">&gt;</span></span></span>
<span class="line">    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>packaging</span><span class="token punctuation">&gt;</span></span>jar<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>packaging</span><span class="token punctuation">&gt;</span></span></span>
<span class="line"></span>
<span class="line">    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>properties</span><span class="token punctuation">&gt;</span></span></span>
<span class="line">        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>maven.compiler.source</span><span class="token punctuation">&gt;</span></span>8<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>maven.compiler.source</span><span class="token punctuation">&gt;</span></span></span>
<span class="line">        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>maven.compiler.target</span><span class="token punctuation">&gt;</span></span>8<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>maven.compiler.target</span><span class="token punctuation">&gt;</span></span></span>
<span class="line">        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>project.build.sourceEncoding</span><span class="token punctuation">&gt;</span></span>UTF-8<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>project.build.sourceEncoding</span><span class="token punctuation">&gt;</span></span></span>
<span class="line">        <span class="token comment">&lt;!-- 控制 spark 依赖范围, 本地启动需要为 compile, 其它可为 provided --&gt;</span></span>
<span class="line">        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency.scope</span><span class="token punctuation">&gt;</span></span>compile<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency.scope</span><span class="token punctuation">&gt;</span></span></span>
<span class="line">    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>properties</span><span class="token punctuation">&gt;</span></span></span>
<span class="line"></span>
<span class="line">    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependencies</span><span class="token punctuation">&gt;</span></span></span>
<span class="line">        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">&gt;</span></span></span>
<span class="line">            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>org.apache.spark<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span></span>
<span class="line">            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>spark-sql_2.12<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span></span>
<span class="line">            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">&gt;</span></span>3.5.6<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">&gt;</span></span></span>
<span class="line">            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>scope</span><span class="token punctuation">&gt;</span></span>\${dependency.scope}<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>scope</span><span class="token punctuation">&gt;</span></span></span>
<span class="line">        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">&gt;</span></span></span>
<span class="line"></span>
<span class="line">        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">&gt;</span></span></span>
<span class="line">            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>org.apache.spark<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span></span>
<span class="line">            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>spark-mllib_2.12<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span></span>
<span class="line">            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">&gt;</span></span>3.5.6<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">&gt;</span></span></span>
<span class="line">            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>scope</span><span class="token punctuation">&gt;</span></span>\${dependency.scope}<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>scope</span><span class="token punctuation">&gt;</span></span></span>
<span class="line">        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">&gt;</span></span></span>
<span class="line"></span>
<span class="line">        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">&gt;</span></span></span>
<span class="line">            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>org.apache.spark<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span></span>
<span class="line">            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>spark-streaming-kafka-0-10_2.13<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span></span>
<span class="line">            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">&gt;</span></span>3.5.6<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">&gt;</span></span></span>
<span class="line">        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">&gt;</span></span></span>
<span class="line"></span>
<span class="line">        <span class="token comment">&lt;!--  examples\\jars 中的 jar--&gt;</span></span>
<span class="line">        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">&gt;</span></span></span>
<span class="line">            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>org.apache.spark<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span></span>
<span class="line">            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>spark-examples_2.12<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span></span>
<span class="line">            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">&gt;</span></span>3.5.6<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">&gt;</span></span></span>
<span class="line">            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>scope</span><span class="token punctuation">&gt;</span></span>system<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>scope</span><span class="token punctuation">&gt;</span></span></span>
<span class="line">            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>systemPath</span><span class="token punctuation">&gt;</span></span>\${project.basedir}/libs/spark-examples_2.12-3.5.6.jar<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>systemPath</span><span class="token punctuation">&gt;</span></span></span>
<span class="line">        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">&gt;</span></span></span>
<span class="line">    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependencies</span><span class="token punctuation">&gt;</span></span></span>
<span class="line"></span>
<span class="line"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>project</span><span class="token punctuation">&gt;</span></span></span>
<span class="line"></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>在 Windows 系统启动，需要下载 <code>winutils.exe</code> 文件，<a href="https://github.com/steveloughran/winutils" target="_blank" rel="noopener noreferrer">下载地址</a>。</p><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh" data-title="sh"><pre><code><span class="line"><span class="token comment"># 使用 examples 的 jar</span></span>
<span class="line">D:<span class="token punctuation">\\</span>spark<span class="token punctuation">\\</span>spark-3.5.6-bin-hadoop3<span class="token punctuation">\\</span>bin<span class="token punctuation">\\</span>spark-submit.cmd <span class="token parameter variable">--class</span> org.apache.spark.examples.JavaSparkPi <span class="token parameter variable">--master</span> local<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span> --driver-memory 2g D:<span class="token punctuation">\\</span>spark<span class="token punctuation">\\</span>spark-3.5.6-bin-hadoop3<span class="token punctuation">\\</span>examples<span class="token punctuation">\\</span>jars<span class="token punctuation">\\</span>spark-examples_2.12-3.5.6.jar <span class="token number">100</span></span>
<span class="line"></span>
<span class="line"><span class="token comment"># 使用自己编译出来的 jar</span></span>
<span class="line">D:<span class="token punctuation">\\</span>spark<span class="token punctuation">\\</span>spark-3.5.6-bin-hadoop3<span class="token punctuation">\\</span>bin<span class="token punctuation">\\</span>spark-submit.cmd <span class="token parameter variable">--class</span> org.apache.spark.examples.JavaSparkPi <span class="token parameter variable">--master</span> local<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span> --driver-memory 2g D:<span class="token punctuation">\\</span>spark<span class="token punctuation">\\</span>spark-example<span class="token punctuation">\\</span>target<span class="token punctuation">\\</span>spark-example-1.0.jar <span class="token number">100</span></span>
<span class="line"></span>
<span class="line"><span class="token comment"># Linux bin 目录执行命令</span></span>
<span class="line">./bin/spark-submit <span class="token parameter variable">--class</span> org.apache.spark.examples.JavaSparkPi --driver-memory 2g <span class="token parameter variable">--master</span> local<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span> ./examples/jars/spark-examples_2.12-3.5.6.jar <span class="token number">100</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="spark-submit" tabindex="-1"><a class="header-anchor" href="#spark-submit"><span>spark-submit</span></a></h2><p>自定义的 Spark Application 打包成 jar 后，可以使用 <code>spark-submit</code> 启动</p><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh" data-title="sh"><pre><code><span class="line"><span class="token comment"># linux 启动格式</span></span>
<span class="line">./bin/spark-submit <span class="token punctuation">\\</span></span>
<span class="line">  <span class="token parameter variable">--class</span> <span class="token operator">&lt;</span>main-class<span class="token operator">&gt;</span> <span class="token punctuation">\\</span></span>
<span class="line">  <span class="token parameter variable">--master</span> <span class="token operator">&lt;</span>master-url<span class="token operator">&gt;</span> <span class="token punctuation">\\</span></span>
<span class="line">  --deploy-mode <span class="token operator">&lt;</span>deploy-mode<span class="token operator">&gt;</span> <span class="token punctuation">\\</span></span>
<span class="line">  <span class="token parameter variable">--conf</span> <span class="token operator">&lt;</span>key<span class="token operator">&gt;=</span><span class="token operator">&lt;</span>value<span class="token operator">&gt;</span> <span class="token punctuation">\\</span></span>
<span class="line">  <span class="token punctuation">..</span>. <span class="token comment"># other options</span></span>
<span class="line">  <span class="token operator">&lt;</span>application-jar<span class="token operator">&gt;</span> <span class="token punctuation">\\</span></span>
<span class="line">  <span class="token punctuation">[</span>application-arguments<span class="token punctuation">]</span></span>
<span class="line"></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>以上参数说明：</p><ul><li><code>--class</code>：自定义 Application 的入口，main 所在的类。</li><li><code>--master</code>：集群的地址，<code>local[2]</code> 本地模式；<code>spark://23.195.26.187:7077</code> 表示 spark 集群模式地址。</li><li><code>--deploy-mode</code>：driver 部署的位置，<code>cluster</code> 表示集群的工作节点；<code>client</code>(默认) 在本地作为外部客户端。</li><li><code>--conf</code>：key=value 指定 spark 配置，配置中携带空格，使用 &quot;key=value&quot; 格式；多个参数配置格式：<code>--conf key=value --conf key2=value2</code>。</li><li><code>application-jar</code>：启动 main 方法所有依赖的 jar 路径；执行的路径必须在集群的各个节点都可见。</li><li><code>application-arguments</code>：可选，传递给 main 方法的参数。</li></ul><h3 id="master" tabindex="-1"><a class="header-anchor" href="#master"><span>master</span></a></h3><p>master 支持的 url 格式：</p><table><thead><tr><th>master url</th><th>说明</th></tr></thead><tbody><tr><td>local</td><td>使用一个本地工作线程运行 Spark</td></tr><tr><td>local[K]</td><td>使用 K 个本地工作线程运行 Spark</td></tr><tr><td>local[K,F]</td><td>使用 K 个工作线程和 F 个 maxFailures(最大失败次数) 在本地运行 Spark</td></tr><tr><td>local[*]</td><td>以本地计算机逻辑核心数工作线程本地运行 Spark</td></tr><tr><td>local[*,F]</td><td>以本地计算机逻辑核心数工作线程本地运行 Spark，运行 F 个 maxFailures</td></tr><tr><td>local-cluster[N,C,M]</td><td>用于测试的本地集群模式，在单个 JVM 中模拟一个分布式集群，该集群有 N 个工作线程、每个工作线程有 C 个核心，每个工作线程有 M MB 内存</td></tr><tr><td>spark://HOST:PORT</td><td>连接到 Spark standalone 集群主节点</td></tr><tr><td>spark://HOST1:PORT1,HOST2:PORT2</td><td>通过 Zookeeper 连接到给定的 Spark 独立集群。</td></tr><tr><td>mesos://HOST:PORT</td><td>连接到给定的 Mesos 集群</td></tr><tr><td>yarn</td><td>根据 --deploy-mode ，以 client 或 cluster 连接 YARN 集群。将根据 HADOOP_CONF_DIR 或 YARN_CONF_DIR 变量查找集群位置</td></tr><tr><td>k8s://HOST:PORT</td><td>根据 --deploy-mode ，以 client 或 cluster 连接 k8s集群。HOST和 PORT 指的是 Kubernetes API Server。默认情况下，它使用 TLS 连接。为了强制使用不安全的连接，使用 k8s://http://HOST:PORT</td></tr></tbody></table><h3 id="从文件加载配置" tabindex="-1"><a class="header-anchor" href="#从文件加载配置"><span>从文件加载配置</span></a></h3><p>spark 配置说明：https://spark.apache.org/docs/3.5.6/configuration.html</p><p><code>spark-submit</code> 可以从 properties 文件中加载 Spark Configuration。默认情况下，从 Spark 目录中的 <code>conf/spark-defaults.conf</code> 中读取配置。</p><p><strong>文件中的配置优先级高于命令行的配置。</strong></p><p>可以使用 <code>--verbose</code> 打印更多配置信息。</p><h3 id="依赖管理" tabindex="-1"><a class="header-anchor" href="#依赖管理"><span>依赖管理</span></a></h3><p>使用 <code>spark-submit</code> 时，启动 jar 和 <code>--jar</code> 指定的 jar 会自定传输到集群。<code>--jar</code> 指定的 jar url 地址必须由 <code>,</code> 分割。</p><p>Spark 支持使用不同的 url 协议传播 jar：</p><ul><li><code>file:</code>：在 driver 所在文件系统加载。</li><li><code>hdfs:,http:,https:,ftp:</code>：根据指定的协议拉取 jar。</li><li><code>local:</code>：在工作节点的文件系统加载。</li></ul><p><strong>jars 和文件被复制到执行器节点的工作目录，会占用一定的空间。使用 YARN 部署，会自动进行清理。Spark standalone 模式，可以通过 spark.worker.cleanup.appDataTtl(worker) 配置自动清理。</strong></p><p>也可以通过 <code>--packages groupId:artifactId:version</code> 从仓库下载依赖。</p><h2 id="运行模式" tabindex="-1"><a class="header-anchor" href="#运行模式"><span>运行模式</span></a></h2><h3 id="local" tabindex="-1"><a class="header-anchor" href="#local"><span>Local</span></a></h3><h3 id="spark-standalone" tabindex="-1"><a class="header-anchor" href="#spark-standalone"><span>Spark standalone</span></a></h3><p>Spark 提供的简单的独立集群。</p><p><strong>手动启动集群命令：</strong></p><div class="language-bash" data-highlighter="prismjs" data-ext="sh" data-title="sh"><pre><code><span class="line"><span class="token comment"># 默认 Spark master 端口 7077, UI 端口 8080</span></span>
<span class="line">./sbin/start-master.sh</span>
<span class="line"></span>
<span class="line"><span class="token comment"># 启动工作节点连接到 master</span></span>
<span class="line">./sbin/start-worker.sh <span class="token operator">&lt;</span>master-spark-URL<span class="token operator">&gt;</span></span>
<span class="line"></span>
<span class="line"></span></code></pre></div><p>master 和 worker 启动可配置的参数：<strong>master 启动 host 是主机名，worker 启动的地址需要是主机名或当前 ip，127.0.0.1 无法注册上。</strong></p><table><thead><tr><th>参数</th><th>作用</th></tr></thead><tbody><tr><td>-h host, --host host</td><td>监听的主机，默认主机名</td></tr><tr><td>-p port, --port port</td><td>服务监听的端口，master 默认7077；worker 随机</td></tr><tr><td>--webui-port port</td><td>web UI 端口，master 默认 8080；worker 默认 8081</td></tr><tr><td>-c cores, --cores cores</td><td>仅 worker 生效，Spark 应用允许使用的 CPU 内核数，默认所有可用</td></tr><tr><td>-m mem, --memory mem</td><td>仅 worker 生效，Spark 应用允许使用的内存总量，默认总 RAM -1G</td></tr><tr><td>-d dir, --work-dir dir</td><td>仅 worker 生效，日志输出和 jar保存 目录，默认 SPARK_HOME/work</td></tr><tr><td>--properties-file file</td><td>加载自定义 spark 配置文件路径，默认 conf/spark-defaults.conf</td></tr></tbody></table><h4 id="集群启动脚本" tabindex="-1"><a class="header-anchor" href="#集群启动脚本"><span>集群启动脚本</span></a></h4><p><code>conf/workers</code> 中可以配置 <code>worker</code> 的服务器列表，。默认情况，ssh 是并行，配置的服务器需要设置无密码(使用私钥)访问。可以通过设置环境变量 <code>SPARK_SSH_FOREGROUND =yes</code>，操作每个 ssh 的 worker 串行提供密码。</p><p>配置 <code>conf/workers</code> 文件后，可以通过以下脚本启动或停止集群：</p><ul><li><code>sbin/start-master.sh</code>：启动 master。</li><li><code>sbin/start-workers.sh</code>：启动 <code>conf/workers</code> 配置的所有 workers。</li><li><code>sbin/start-worker.sh</code>：启动 worker。</li><li><code>sbin/start-connect-server.sh</code>：启动 Spark Connect。</li><li><code>sbin/start-all.sh</code>：启动 master 和 配置的 workers。</li><li><code>sbin/stop-master.sh</code>：停止 <code>start-master.sh</code> 启动的 master。</li><li><code>sbin/stop-worker.sh</code>：停止所有 workers。</li><li><code>sbin/stop-workers.sh</code>：停止 <code>conf/workers</code> 配置的 workers。</li><li><code>sbin/stop-connect-server.sh</code>：停止 Spark Connect。</li><li><code>sbin/stop-all.sh</code>：停止 master 和所有 workers。</li></ul><p><code>conf/spark-env.sh</code> 可以配置 Spark 集群。模板文件名 <code>conf/spark-env.sh.template</code>。</p><table><thead><tr><th>变量名</th><th>作用</th></tr></thead><tbody><tr><td><code>SPARK_MASTER_HOST</code></td><td>master 监听的地址</td></tr><tr><td><code>SPARK_MASTER_PORT</code></td><td>master 启动的端口 (默认 7077)</td></tr><tr><td><code>SPARK_MASTER_WEBUI_PORT</code></td><td>master web UI (默认 8080)</td></tr><tr><td><code>SPARK_MASTER_OPTS</code></td><td>配置 master 参数，格式 &quot;-Dx=y&quot; (默认 none)</td></tr><tr><td><code>SPARK_LOCAL_DIRS</code></td><td>master</td></tr><tr><td><code>SPARK_WORKER_CORES</code></td><td>Spark 应用可使用的核心数 (默认 all available cores)</td></tr><tr><td><code>SPARK_WORKER_MEMORY</code></td><td>worker 分配的内存</td></tr><tr><td><code>SPARK_WORKER_PORT</code></td><td>worker 启动占用的端口 (默认 random)</td></tr><tr><td><code>SPARK_WORKER_WEBUI_PORT</code></td><td>worker web UI (默认 8081)</td></tr><tr><td><code>SPARK_WORKER_DIR</code></td><td>worker 日志和 jar 的缓存目录 (默认 SPARK_HOME/work)</td></tr><tr><td><code>SPARK_WORKER_OPTS</code></td><td>配置 worker 参数，格式 &quot;-Dx=y&quot; (默认 none)</td></tr><tr><td><code>SPARK_DAEMON_MEMORY</code></td><td>master 和 worker 进程分配的内存 (默认 1g)</td></tr><tr><td><code>SPARK_DAEMON_JAVA_OPTS</code></td><td>master 和 worker 进程 JVM 启动参数，格式 &quot;-Dx=y&quot; (默认 none)</td></tr><tr><td><code>SPARK_DAEMON_CLASSPATH</code></td><td>master 和 worker 进程的类路径(默认 none)</td></tr><tr><td><code>SPARK_PUBLIC_DNS</code></td><td>Spark master 和 worker 的公共 DNS 名称 (默认 none)</td></tr></tbody></table><p><code>SPARK_MASTER_OPTS</code> 支持的参数</p><table><thead><tr><th>属性</th><th>默认值</th><th>说明</th></tr></thead><tbody><tr><td><code>spark.master.ui.port</code></td><td><code>8080</code></td><td></td></tr><tr><td><code>spark.master.ui.decommission.allow.mode</code></td><td><code>LOCAL</code></td><td>master Web UI /workers/kill 功能配置. <code>LOCAL</code> <code>DENY</code> <code>ALLOW</code></td></tr><tr><td><code>spark.master.rest.enabled</code></td><td><code>false</code></td><td>是否使用 Master REST API</td></tr><tr><td><code>spark.master.rest.port</code></td><td><code>6066</code></td><td>Master REST API 端口</td></tr><tr><td><code>spark.deploy.retainedApplications</code></td><td>200</td><td>显示的已完成应用程序的最大数目，旧的删除</td></tr><tr><td><code>spark.deploy.retainedDrivers</code></td><td>200</td><td>显示的已完成 driver 的最大数目，旧的删除</td></tr><tr><td><code>spark.deploy.spreadOut</code></td><td>true</td><td>spread</td></tr><tr><td><code>spark.deploy.defaultCores</code></td><td>(infinite)</td><td>CPU core 相关</td></tr><tr><td><code>spark.deploy.maxExecutorRetries</code></td><td>10</td><td>执行失败次数相关</td></tr><tr><td><code>spark.worker.timeout</code></td><td>60</td><td>master 和 worker 之间的心跳间隔时间</td></tr><tr><td><code>spark.worker.resource.{name}.amount</code></td><td>(none)</td><td></td></tr><tr><td><code>spark.worker.resource.{name}.discoveryScript</code></td><td>(none)</td><td>worker 启动查询特点脚本</td></tr><tr><td><code>spark.worker.resourcesFile</code></td><td>(none)</td><td></td></tr></tbody></table><p><code>SPARK_WORKER_OPTS</code> 支持配置项</p><table><thead><tr><th>属性名</th><th>默认值</th><th>说明</th></tr></thead><tbody><tr><td><code>spark.worker.cleanup.enabled</code></td><td>false</td><td>是否自动清理工作目录</td></tr><tr><td><code>spark.worker.cleanup.interval</code></td><td>1800s</td><td>清理间隔时间</td></tr><tr><td><code>spark.worker.cleanup.appDataTtl</code></td><td>604800s</td><td>文件有效期</td></tr><tr><td><code>spark.shuffle.service.db.enabled</code></td><td>true</td><td></td></tr><tr><td><code>spark.shuffle.service.db.backend</code></td><td>LEVELDB</td><td></td></tr><tr><td><code>spark.storage.cleanupFilesAfterExecutorExit</code></td><td>true</td><td></td></tr><tr><td><code>spark.worker.ui.compressedLogFileLengthCacheSize</code></td><td>100</td><td></td></tr></tbody></table><h3 id="hadoop-yarn" tabindex="-1"><a class="header-anchor" href="#hadoop-yarn"><span>Hadoop YARN</span></a></h3><h3 id="kubernetes" tabindex="-1"><a class="header-anchor" href="#kubernetes"><span>Kubernetes</span></a></h3>`,65)]))}const i=s(p,[["render",l],["__file","spark.html.vue"]]),r=JSON.parse('{"path":"/spark/spark.html","title":"Spark","lang":"zh-CN","frontmatter":{},"headers":[{"level":2,"title":"Spark 介绍","slug":"spark-介绍","link":"#spark-介绍","children":[]},{"level":2,"title":"Quick Start","slug":"quick-start","link":"#quick-start","children":[{"level":3,"title":"自定义 Application","slug":"自定义-application","link":"#自定义-application","children":[]}]},{"level":2,"title":"spark-submit","slug":"spark-submit","link":"#spark-submit","children":[{"level":3,"title":"master","slug":"master","link":"#master","children":[]},{"level":3,"title":"从文件加载配置","slug":"从文件加载配置","link":"#从文件加载配置","children":[]},{"level":3,"title":"依赖管理","slug":"依赖管理","link":"#依赖管理","children":[]}]},{"level":2,"title":"运行模式","slug":"运行模式","link":"#运行模式","children":[{"level":3,"title":"Local","slug":"local","link":"#local","children":[]},{"level":3,"title":"Spark standalone","slug":"spark-standalone","link":"#spark-standalone","children":[]},{"level":3,"title":"Hadoop YARN","slug":"hadoop-yarn","link":"#hadoop-yarn","children":[]},{"level":3,"title":"Kubernetes","slug":"kubernetes","link":"#kubernetes","children":[]}]}],"git":{"updatedTime":1759127661000,"contributors":[{"name":"ouyangcm","username":"ouyangcm","email":"mingorg@163.com","commits":3,"url":"https://github.com/ouyangcm"},{"name":"oycm","username":"oycm","email":"1164864987@qq.com","commits":2,"url":"https://github.com/oycm"}]},"filePathRelative":"spark/spark.md"}');export{i as comp,r as data};
